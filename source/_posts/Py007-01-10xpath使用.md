---
title: Py007-01-10xpath使用
date: 2018-11-30 23:11:36
tags: M07
---

### xpath在爬虫中使用流程

```
- 1.下载: pip install lxml
- 2.导包: from lxml import etree
- 3.创建etree对象 进行指定数据的解析
    - 本地   etree = etree.parse('本地文件路径')
            etree.xpath('xpath表达式')
    - 网络   etree = etree.HTML('网络请求到的页面数据')
            etree.xpath('xpath表达式')
```

> #### 常用xpath表达式

```

属性定位：
    #找到class属性值为song的div标签
    //div[@class="song"] 
层级&索引定位：
    #找到class属性值为tang的div的直系子标签ul下的第二个子标签li下的直系子标签a
    //div[@class="tang"]/ul/li[2]/a
逻辑运算：
    #找到href属性值为空且class属性值为du的a标签
    //a[@href="" and @class="du"]
模糊匹配：
    # 当前所有div 同时class属性包含了 ng  
    # 如 <div class="song"> 和<div class="tang"> 都会被匹配
    //div[contains(@class, "ng")]
    # 当前所有div 的class属性 以 ta开头的
    //div[starts-with(@class, "ta")]
取文本：
    # /表示获取某个标签下的文本内容
    //div[@class="song"]/p[1]/text()
    # //表示获取某个标签下的文本内容和所有子标签下的文本内容
    //div[@class="tang"]//text()
取属性：
    //div[@class="tang"]//li[2]/a/@href
```

#### xpath插件

我们不可能每次都把html下载到本地  来写xpath表达式

> xpath插件可以直接作用在浏览器当中来校验xpath表达式

- 安装

```
1. 更多工具
2. 扩展程序
3. 开启开发者模式
4. XPath Helper 找到它 安装
5. 快捷键
    - 开启和关闭 xpath插件  ctrl + shift + x
```

#### 段子网的段子内容和标题解析

- https://ishuo.cn/joke

```
#!/usr/bin/env python
#-*- encoding:utf-8 -*-

from lxml import etree
import requests
# 1. 指定url
url='https://ishuo.cn/joke'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
}
# 2 发请求
response=requests.get(url,headers=headers).text
# 3 获取页面内容
page_text = response.text
#4 解析
tree=etree.HTML(page_text)
# 获取所有li
li_list=tree.xpath('//div[@id="list"]/ul/li')
# 注意 Element类型对象可以继续用xpath函数，该对象表示的局部内容进行指定内容的解析

fp = open('./duanzi.txt','w',encoding='utf-8')

for li in li_list:
    content = li.xpath('./div[@class="content"]/text()')[0]
    title = li.xpath('./div[@class="info"]/a/text()')[0]
    # 5 持久化
    fp.write(title+':'+content+'\n\n')
    print('写入成功')

```